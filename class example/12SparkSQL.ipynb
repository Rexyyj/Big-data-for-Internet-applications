{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# spark = SparkSession.builder.getOrCreate()\n",
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Creating dataframes form csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|   name| age|\n",
      "+-------+----+\n",
      "|   Andy|  30|\n",
      "|Michael|null|\n",
      "| Justin|  19|\n",
      "|Michael|null|\n",
      "+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "df = spark.read.load(\"persons.csv\",\n",
    "                        format=\"csv\",\n",
    "                        header=True,\n",
    "                        inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(name='Andy', age=30)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Creating DataFrames from RDD or python lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|  19| Justin|\n",
      "|  30|   Andy|\n",
      "|null|Michael|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark2 = SparkSession.builder.getOrCreate()\n",
    "profilesList = [(19, \"Justin\"), (30, \"Andy\"),(None, \"Michael\")]\n",
    "df = spark2.createDataFrame(profilesList,[\"age\",\"name\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From dataframe to RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(name='Andy', age=30), Row(name='Michael', age=None), Row(name='Justin', age=19), Row(name='Michael', age=None)]\n",
      "['Andy', 'Michael', 'Justin', 'Michael']\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "df = spark.read.load( \"persons.csv\",\n",
    "                        format=\"csv\",\n",
    "                        header=True,\n",
    "                        inferSchema=True)\n",
    "rddRows = df.rdd\n",
    "print(rddRows.collect())\n",
    "rddNames = rddRows.map(lambda row: row.name)\n",
    "print(rddNames.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Operations on dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|   name| age|\n",
      "+-------+----+\n",
      "|   Andy|  30|\n",
      "|Michael|null|\n",
      "| Justin|  19|\n",
      "|Michael|null|\n",
      "+-------+----+\n",
      "\n",
      "+-------+----+\n",
      "|   name| age|\n",
      "+-------+----+\n",
      "|   Andy|  30|\n",
      "|Michael|null|\n",
      "+-------+----+\n",
      "only showing top 2 rows\n",
      "\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.show()\n",
    "df.show(2)\n",
    "df.printSchema()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|   name| age|\n",
      "+-------+----+\n",
      "|Michael|null|\n",
      "| Justin|  19|\n",
      "|   Andy|  30|\n",
      "+-------+----+\n",
      "\n",
      "+-------+\n",
      "|   name|\n",
      "+-------+\n",
      "|   Andy|\n",
      "|Michael|\n",
      "| Justin|\n",
      "|Michael|\n",
      "+-------+\n",
      "\n",
      "+-------+-------+\n",
      "|   name|new_age|\n",
      "+-------+-------+\n",
      "|   Andy|     31|\n",
      "|Michael|   null|\n",
      "| Justin|     20|\n",
      "|Michael|   null|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.distinct().show()\n",
    "df.select(\"name\").show()\n",
    "df.selectExpr(\"name\",\"age+1 AS new_age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|name|age|\n",
      "+----+---+\n",
      "|Andy| 30|\n",
      "+----+---+\n",
      "\n",
      "+----+---+\n",
      "|name|age|\n",
      "+----+---+\n",
      "|Andy| 30|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"age>=25 and age<=40\").show()\n",
    "df.where(\"age>=25 and age<=40\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+-------+\n",
      "|   name| age|     sport|   name|\n",
      "+-------+----+----------+-------+\n",
      "| Justin|  19|       ski| Justin|\n",
      "|   Andy|  30|basketball|   Andy|\n",
      "|Michael|null|  swimming|Michael|\n",
      "|Michael|null|  swimming|Michael|\n",
      "+-------+----+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark4 = SparkSession.builder.getOrCreate()\n",
    "sport_to_match = [(\"ski\", \"Justin\"), (\"basketball\", \"Andy\"),(\"swimming\", \"Michael\")]\n",
    "df4 = spark4.createDataFrame(sport_to_match,[\"sport\",\"name\"])\n",
    "dfJoin= df.join(df4, df.name==df4.name)\n",
    "dfJoin.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|avg(age)|\n",
      "+--------+\n",
      "|    24.5|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avg_age = df.agg({\"age\":\"avg\"})\n",
    "avg_age.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|   name|avg(age)|\n",
      "+-------+--------+\n",
      "|Michael|    null|\n",
      "|   Andy|    30.0|\n",
      "| Justin|    19.0|\n",
      "+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "groupped = df.groupBy(\"name\").avg(\"age\")\n",
    "groupped.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------+\n",
      "|   name|count(name)|avg(age)|\n",
      "+-------+-----------+--------+\n",
      "|Michael|          2|    null|\n",
      "|   Andy|          1|    30.0|\n",
      "| Justin|          1|    19.0|\n",
      "+-------+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"name\").agg({\"age\":\"avg\",\"name\":\"count\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|   name| age|\n",
      "+-------+----+\n",
      "|   Andy|  30|\n",
      "| Justin|  19|\n",
      "|Michael|null|\n",
      "|Michael|null|\n",
      "+-------+----+\n",
      "\n",
      "+-------+----+\n",
      "|   name| age|\n",
      "+-------+----+\n",
      "|Michael|null|\n",
      "|Michael|null|\n",
      "| Justin|  19|\n",
      "|   Andy|  30|\n",
      "+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(\"name\").show()\n",
    "df.sort(\"name\",ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dataframe and SQL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|  19| Justin|\n",
      "|  30|   Andy|\n",
      "|null|Michael|\n",
      "|  40| Justin|\n",
      "+----+-------+\n",
      "\n",
      "+---+----+\n",
      "|age|name|\n",
      "+---+----+\n",
      "| 30|Andy|\n",
      "+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark3 = SparkSession.builder.getOrCreate()\n",
    "profilesList3 = [(19, \"Justin\"), (30, \"Andy\"),(None, \"Michael\"),(40, \"Justin\")]\n",
    "df3 = spark3.createDataFrame(profilesList3,[\"age\",\"name\"])\n",
    "df3.show()\n",
    "\n",
    "df3.createOrReplaceTempView(\"people\")\n",
    "selectedPersons=spark3.sql(\"SELECT * FROM people WHERE age>20 and age<40\")\n",
    "selectedPersons.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|   sport|   name|\n",
      "+--------+-------+\n",
      "|swimming| Justin|\n",
      "| jogging|   Andy|\n",
      "| running|Michael|\n",
      "+--------+-------+\n",
      "\n",
      "+----+-------+--------+-------+\n",
      "| age|   name|   sport|   name|\n",
      "+----+-------+--------+-------+\n",
      "|null|Michael| running|Michael|\n",
      "|  30|   Andy| jogging|   Andy|\n",
      "|  19| Justin|swimming| Justin|\n",
      "|  40| Justin|swimming| Justin|\n",
      "+----+-------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Operation on two data frame\n",
    "profilesList4 = [(\"swimming\", \"Justin\"), (\"jogging\", \"Andy\"),(\"running\", \"Michael\")]\n",
    "df4  =  spark3.createDataFrame(profilesList4,[\"sport\",\"name\"])\n",
    "df4.show()\n",
    "df4.createOrReplaceTempView(\"LikeSport\")\n",
    "\n",
    "dfPersonLikes=spark3.sql(\"SELECT * FROM people,LikeSport where people.name=LikeSport.name\")\n",
    "dfPersonLikes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-----------+\n",
      "|   name|avg(age)|count(name)|\n",
      "+-------+--------+-----------+\n",
      "|Michael|    null|          1|\n",
      "|   Andy|    30.0|          1|\n",
      "| Justin|    29.5|          2|\n",
      "+-------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nameAvgAgeCount=spark3.sql(\"SELECT name,avg(age),count(name) FROM people GROUP BY name\")\n",
    "nameAvgAgeCount.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* save dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameAvgAgeCount.rdd.saveAsTextFile(\"./nameAvgCount.txt\")\n",
    "nameAvgAgeCount.write.csv(\"./nameAvgCount.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Row(name='Michael', avg(age)=None, count(name)=1)\", \"Row(name='Andy', avg(age)=30.0, count(name)=1)\", \"Row(name='Justin', avg(age)=29.5, count(name)=2)\"]\n",
      "+-------+--------+-----------+\n",
      "|   name|avg(age)|count(name)|\n",
      "+-------+--------+-----------+\n",
      "| Justin|    29.5|          2|\n",
      "|Michael|    null|          1|\n",
      "|   Andy|    30.0|          1|\n",
      "+-------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd_load=sc.textFile(\"nameAvgCount.txt\")\n",
    "print(rdd_load.collect())\n",
    "df_reload = spark.read.load(\"./nameAvgCount.csv\",\n",
    "                           format=\"csv\",\n",
    "                           header=True,\n",
    "                            inferSchema=True)\n",
    "df_reload.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* UDF: User Defined Funcitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|size|\n",
      "+----+\n",
      "|   6|\n",
      "|   7|\n",
      "|   4|\n",
      "+----+\n",
      "\n",
      "+------------+\n",
      "|length(name)|\n",
      "+------------+\n",
      "|           6|\n",
      "|           4|\n",
      "|           7|\n",
      "|           6|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define\n",
    "spark.udf.register(\"length\",lambda x:len(x))\n",
    "# use\n",
    "result = df_reload.selectExpr(\"length(name) as size\")\n",
    "result.show()\n",
    "\n",
    "result = spark.sql(\"SELECT length(name) FROM people\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
