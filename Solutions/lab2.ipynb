{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To look at some lines of the file we can use 'take' action: \n",
      "['have\\t338996', 'bought\\t46988', 'several\\t19688']\n",
      "The number of words containing in the file is:  339819\n"
     ]
    }
   ],
   "source": [
    "inputRDD=sc.textFile(\"/data/students/bigdata_internet/lab2/word_frequency.tsv\")\n",
    "print(\"To look at some lines of the file we can use 'take' action: \")\n",
    "print(inputRDD.take(3))\n",
    "print(\"The number of words containing in the file is: \",inputRDD.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter words starting with a specified prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of selected lines=1607\n"
     ]
    }
   ],
   "source": [
    "PREFIX = \"bo\"\n",
    "def checkPrefix(str):\n",
    "    temp = str[0:len(PREFIX)]\n",
    "    if temp == PREFIX:\n",
    "        return True\n",
    "    return False\n",
    "filteredRDD = inputRDD.filter(checkPrefix)\n",
    "print(\"Number of selected lines=\"+str(filteredRDD.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maxfreq=47753\n"
     ]
    }
   ],
   "source": [
    "wordFreqMapRDD=filteredRDD.map(lambda line:line.split('\\t'))\n",
    "sortedFreqRDD = wordFreqMapRDD.sortBy(lambda e:int(e[1]),ascending=False)\n",
    "print(\"Maxfreq=\"+str(sortedFreqRDD.take(1)[0][1]))\n",
    "maxfreq =int(sortedFreqRDD.take(1)[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['bought', '46988'], ['box', '47753']]\n"
     ]
    }
   ],
   "source": [
    "def checkFreq(elem):\n",
    "    if int(elem[1])>0.8*maxfreq:\n",
    "        return True\n",
    "    return False\n",
    "frequentWordRDD = wordFreqMapRDD.filter(checkFreq)\n",
    "print(frequentWordRDD.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the remaining words and save the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of selected lines = 2\n"
     ]
    }
   ],
   "source": [
    "print(\"num of selected lines = \"+str(frequentWordRDD.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedWordRDD = frequentWordRDD.map(lambda elem:elem[0])\n",
    "selectedWordRDD.saveAsTextFile(\"./lab2/ex1.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the application in different ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hot\\t32944', 'home\\t17995', 'however\\t12492']\n",
      "number of selected lines=1519\n"
     ]
    }
   ],
   "source": [
    "PREFIX = \"ho\"\n",
    "filteredRDD = inputRDD.filter(checkPrefix)\n",
    "print(filteredRDD.take(3))\n",
    "print(\"number of selected lines=\"+str(filteredRDD.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python script:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "import sys\n",
    "conf = SparkConf().setAppName(\"My app\")\n",
    "sc = SparkContext(conf = conf)\n",
    "\n",
    "inputRDD=sc.textFile(\"/data/students/bigdata_internet/lab2/word_frequency.tsv\")\n",
    "PREFIX =sys.argv[1]\n",
    "def checkPrefix(str):\n",
    "    temp = str[0:len(PREFIX)]\n",
    "    if temp == PREFIX:\n",
    "        return True\n",
    "    return False\n",
    "filteredRDD = inputRDD.filter(checkPrefix)\n",
    "filteredRDD.saveAsTextFile(sys.argv[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Command to run the script:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s287513@jupyter-s287513:~/lab2$ spark-submit --master local --deploy-mode client problem2-2.py ho ./lab2/2-2\n",
    "\n",
    "s287513@jupyter-s287513:~/lab2$ spark-submit --master yarn --deploy-mode client problem2-2.py ho ./lab2/2-2-re         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A1: When using \"--master local\", the execution of the script is faster than using \"--master yarn\". \n",
    "    The possible explanation is that the time used to transmit the script to yarn cluster is much more then the execution time of the script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2:Yes, I would cache filteredRDD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total word number=45444841\n"
     ]
    }
   ],
   "source": [
    "inputRDD = sc.textFile(\"/data/students/bigdata_internet/lab2/finefoods_text.txt\")\n",
    "def toWord(line):\n",
    "    words=[]\n",
    "    for word in line.split(' '):\n",
    "        if word != '':\n",
    "            words.append(word)\n",
    "    return words\n",
    "wordRDD = inputRDD.flatMap(toWord)\n",
    "print(\"Total word number=\"+str(wordRDD.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('have', 338996), ('bought', 46988), ('several', 19688), ('of', 792000), ('Vitality', 252)]\n"
     ]
    }
   ],
   "source": [
    "wordOnePairRDD = wordRDD.map(lambda word: (word,1))\n",
    "wordFreqRDD = wordOnePairRDD.reduceByKey(lambda v1,v2:v1+v2)\n",
    "print(wordFreqRDD.take(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
